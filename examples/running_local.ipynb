{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b45eae3",
   "metadata": {},
   "source": [
    "# Rodar localmente a avaliação\n",
    "\n",
    "Escolha alguma DL e faça um gitclone do repositório: https://github.com/mrai-research/lm-evaluation-harness-competition\n",
    "\n",
    "Crie um conda environment com Python >= 3.9 e instale torch + cudann. Certifique-se de que o cudann está de acordo com a GPU da DL que você está usando.\n",
    "\n",
    "Acesse o root do repositório para instalar a biblioteca:\n",
    "\n",
    "```bash\n",
    "cd lm-evaluation-harness-competition\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "Basta acessar esse notebook para executar a avaliação usando o comando de linha `lm-eval`. O comando tem os seguintes parâmetros:\n",
    "\n",
    "- `model`: será sempre `hf`, é a classe de modelos que estamos usando\n",
    "- `model_args`: é a configuração do modelo. Utilize sempre `pretrained/hadatasets/morai/$modelarch/,dtype=bfloat16,subfolder=iter_$iter` onde você deve substituir $modelarch por uma das 6 arquiteturas disponíveis e $iter pelo número de passos de treinamento. O parâmetro \"dtype=bfloat16\" serve para utilizar o modelo quantizado.\n",
    "- `tasks`: tarefa que está definida com um arquivo `yaml` dentro da pasta `tasks`\n",
    "- `batch_size`: número de entradas passadas simultaneamente para o modelo. Se usar \"auto\", o sistema irá usar o número máximo possível.\n",
    "- `output_path`: onde salvar os jsons resultados da avaliação.\n",
    "- `log_samples`: retorna o resultado para cada entrada. Não precisa adicionar algum argumento, apenas adicionar a flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f6936e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LOGLEVEL=DEBUG\n",
      "2025-09-03:16:41:49 DEBUG    [tasks:539] File _evalita-mp_ner_wn.yaml in /work/giovani.valdrighi/lm-evaluation-harness-competition/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-09-03:16:41:49 DEBUG    [tasks:539] File _evalita-mp_ner_adg.yaml in /work/giovani.valdrighi/lm-evaluation-harness-competition/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-09-03:16:41:49 DEBUG    [tasks:539] File _evalita-mp_ner_fic.yaml in /work/giovani.valdrighi/lm-evaluation-harness-competition/lm_eval/tasks/evalita_llm could not be loaded\n",
      "Selected Tasks: ['mmlu_var5shots_astronomy']\n",
      "2025-09-03:16:41:52 INFO     [evaluator:189] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2025-09-03:16:41:52 INFO     [evaluator:227] Initializing hf model, with arguments: {'pretrained': '/hadatasets/morai/dense-1b-arch1/', 'dtype': 'bfloat16', 'subfolder': 'iter_0024000'}\n",
      "2025-09-03:16:41:53 INFO     [models.huggingface:137] Using device 'cuda'\n",
      "2025-09-03:16:41:53 DEBUG    [models.huggingface:499] Using model type 'causal'\n",
      "2025-09-03:16:41:53 INFO     [models.huggingface:383] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "`trust_remote_code` is not supported anymore.\n",
      "Please check that the Hugging Face dataset 'hails/mmlu_no_train' isn't based on a loading script and remove `trust_remote_code`.\n",
      "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n",
      "2025-09-03:16:42:14 ERROR    [datasets.load:1367] `trust_remote_code` is not supported anymore.\n",
      "Please check that the Hugging Face dataset 'hails/mmlu_no_train' isn't based on a loading script and remove `trust_remote_code`.\n",
      "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n",
      "2025-09-03:16:42:17 DEBUG    [api.task:884] No custom filters defined. Using default 'take_first' filter for handling repeats.\n",
      "2025-09-03:16:42:17 INFO     [api.task:434] Building contexts for mmlu_var5shots_astronomy on rank 0...\n",
      "100%|█████████████████████████████████████████| 152/152 [00:02<00:00, 74.89it/s]\n",
      "2025-09-03:16:42:19 DEBUG    [evaluator:530] Task: mmlu_var5shots_astronomy; number of requests on this rank: 608\n",
      "2025-09-03:16:42:19 INFO     [evaluator:559] Running loglikelihood requests\n",
      "Running loglikelihood requests:   0%|                   | 0/608 [00:00<?, ?it/s]Passed argument batch_size = auto:1. Detecting largest batch size\n",
      "Determined largest batch size: 64\n",
      "Running loglikelihood requests: 100%|█████████| 608/608 [01:33<00:00,  6.51it/s]\n",
      "2025-09-03:16:43:55 DEBUG    [models.huggingface:1474] Failed to get model SHA for /hadatasets/morai/dense-1b-arch1/ at revision main. Error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/hadatasets/morai/dense-1b-arch1/'. Use `repo_type` argument if needed.\n",
      "2025-09-03:16:44:17 INFO     [loggers.evaluation_tracker:209] Saving results aggregated\n",
      "2025-09-03:16:44:17 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: mmlu_var5shots_astronomy\n",
      "hf (pretrained=/hadatasets/morai/dense-1b-arch1/,dtype=bfloat16,subfolder=iter_0024000), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto (64)\n",
      "|  Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
      "|---------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
      "|astronomy|      1|none  |     5|acc     |↑  |0.3355|±  |0.0384|\n",
      "|         |       |none  |     5|acc_norm|↑  |0.4342|±  |0.0403|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%env LOGLEVEL=DEBUG\n",
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained=/hadatasets/morai/dense-1b-arch1/,dtype=bfloat16,subfolder=iter_0024000 \\\n",
    "    --tasks mmlu_var5shots_astronomy \\\n",
    "    --batch_size auto \\\n",
    "    --log_samples \\\n",
    "    --output_path results/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e2lm_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
